---
title: "Generate data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Generate data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(oscbvar)
```

This vignette goes through how to generate data for the paper: from (atomic) agent predictions, to the full data set including aggregation based methods.

## Generate the agent predictions

Agent predictions are generated using the *gen_atomic_preds* function, which requires two inputs: a list of models for which to generate predictions for (a list of available models can be obtained using the *gen_atomic_list()* function) and a list of settings (the starting point, the minimum estimation size before prediction starts, whether to use a rolling estimation window or not, and which column contains the response variable). The function uses the macrodata set.

```{r, eval = FALSE}
menu <- gen_atomic_list()
list_of_models <- menu[c(2, 6, 9, 10)]
atomic_settings <- list(5, 60, FALSE, 1)
pred_data <- gen_atomic_preds(list_of_models, atomic_settings)
```

This will return a data frame on the format

```{r, include = TRUE, echo = FALSE}
#?builhead(atomdat_2)
```

## Generate aggregate predictions

Aggregate predictions come in two types. The first type is *baseline predictions* which are the two static pooling methods *equal weights* and *gewisano* (Geweke and Amisano's static otpimal linear pools). The second type is (dynamic) caliper pools.

The generation of aggregate predictions using the caliper methods goes through three steps. First we create a weight data frame using the function caliper_relevance, these weights are then combined with atomic predictions (historical data) to create what used to be call relevance-adjusted log scores. These relevance adjusted log scores are then used to create weights using the function gen_RAA, which then sends us to the propto_weighting function that calculates log predictive densities and predictive means. So propto_weighting calculates the final predictions, and as it does that it sort of calculates the weights as a by-product, adn thus we cannot really reach in there and get the weights out.

### Taking a look at the weights over time

To get to the weights we need a data frame of atomic predictions, a data frame of smoothing variables, a time to start aggregating, a caliper width and a mvc. To get to the weights we simply need to first generate a weight matrix,then call RAL_calculator with that weight df and the atomic data frame, then manipulate the data frame we get back.